{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FO0vSGFIA1e"
   },
   "source": [
    "# Fake News Generator & Detector using GPT-2 and BERT\n",
    "\n",
    "This project presents an interactive system that combines two powerful Natural Language Processing (NLP) models to address the problem of **fake news**:\n",
    "\n",
    "- **Fake News Generation**: Using the GPT-2 language model, the system can generate synthetic news headlines based on a given prompt. This demonstrates how easily fake news can be created with modern generative AI.\n",
    "  \n",
    "- **Fake News Detection**: A fine-tuned BERT model is used to classify whether a given news headline is *real* or *fake*, helping showcase how AI can also be leveraged to combat misinformation.\n",
    "\n",
    "The interface is built using **Gradio**, enabling an intuitive and accessible way to interact with both functionalities without writing any code.\n",
    ">\n",
    "---\n",
    "\n",
    "## How to Use:\n",
    "1. Run the notebook step-by-step from top to bottom.\n",
    "2. The final cell will launch a simple interface where you can:\n",
    "   - Generate fake news headlines.\n",
    "   - Detect if a headline is real or fake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_yqXNIcH0G8"
   },
   "source": [
    "## Step 1 : Install & Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zI_zNdvMHY_x",
    "outputId": "8c8ebee6-0dab-4561-84bf-6542bdf802bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets torch gradio --quiet\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "import torch\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCRbPIlcIzyS"
   },
   "source": [
    "## Step 2 :  Loading Pretrained GPT-2 and BERT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483,
     "referenced_widgets": [
      "3245c86c631941029b478ebef524a22b",
      "66caefa6e9914fafa3f7712525a259b6",
      "437b3450c2834339ad0e6936ea88b8ee",
      "81116e9d679f44b2a2806fa3ffe172b4",
      "ce3bab1a11dc4cac89303c9e4809149a",
      "dcf91770048445788c7f92040fbd3bc2",
      "02ab12ae401c4cf6bf9a10096af74d69",
      "4bb94c061a67487a860b021e0a75d4fe",
      "56c18d629a0f4dc48e208487e0638ba8",
      "6e5e2713ec654dc0a8dab1bf5e6c2788",
      "fed5f23ffd38427da77be21e4fe7b24e",
      "dc85e69fd6974d0c84f4d74607a3cce7",
      "c5ec5f28ce764455852e9fab89c33347",
      "cb5c8387ea324f928732ef3859205fa1",
      "8244913e48094e7c9204d0e35cc1ccb4",
      "aa2433da2958425f9f54695518d1cb10",
      "242caf27429945259117397444406a4b",
      "762d46d5dd6f4beb90589f7f5a86adfd",
      "3bcfbc2d4c974ff2b67a278579894af0",
      "dc431f730fb54bcd9b734e20206ae7b9",
      "564b6a0b46a941c49306cdddd545214d",
      "1fac61daad8f478aa00dc97bb29e1069",
      "fe4c171ce0884d91a8a33e4f73b069d0",
      "91346ef8ba744a40919e80b6b9cbb442",
      "e5f3f19ac422440abbb042718e25ae7d",
      "328bef604a2c4c50b6fd1722c8bafef7",
      "38ef2cdbf4454452839a097be5959642",
      "b2bf0bd0005d4e22905243c889120928",
      "6d84381127494535a3dfe10884adadf5",
      "ff49afb1fe0b4e088297673b0ac3d603",
      "61343deb20b24f38b31f224f807069bb",
      "392fa03712a14a3fb58fca98f5bba7e3",
      "a435f943bf934e7b8514038be6562199",
      "65bf21eaed7c4753808998466752329f",
      "22ea76fc2d2c4103b46b3be1dea62492",
      "65dfbbf55ff9434eb027269c4546866b",
      "49c6378ca64844b6b6eccbe1238f98ae",
      "ad115cc07d3a441e9704d3225a73e50f",
      "a56e195cede34532a643a7a6c59c1ef1",
      "f7e9ca800bcd4215843f6dc1c9b630b2",
      "1553b83824ea44c0b98e29ad9dcec3d4",
      "497eb2ead4494a75bc90e28b44f54ac8",
      "b3bd39dfb29f49249dc5b16df5dbdd19",
      "cedcbf7d868c45c6a21991777669c109",
      "30043d448529466ca4ae867e6a776faf",
      "4bb1212f5ae1486fb17c334ecb490385",
      "fb173ffa90564413a2a8210f44c04ede",
      "2f24835fa6244e9c8fba93be73309210",
      "7daa870d9ee04e76894aa5382e3c2718",
      "0f7b3ee6699d45c486958eaf90db4c4b",
      "fd00f03b054f44afbb0cef4b3307876d",
      "d03a70a5c5d944dba60e011c5c8f2877",
      "f675dddcfa4b4e24943615b96c1ed4f4",
      "30e81f5956604ba4995a08f295c8ca63",
      "fc96106d66094319a22fe2485c4df2e3",
      "61358764a1384b4f904c8cdadf3f9cd3",
      "c95b249b4c6940a4a6e58f56a58df09c",
      "06ea9ba7d7ba4670af278eb2ba16dc30",
      "5fd3a34423b849829666ef2b4d7bbc19",
      "4bcf57a775a64ee2a7f630ed9b65ad34",
      "5283dbba635f45cfaaec78b77ef6ed05",
      "1bd263c0c82a4a55bf8037a2f1237651",
      "558e52f20d2e482289c3d377431d3e89",
      "2929bdb6e7c34e95a56c136e3c27d65b",
      "621f1ea69d0b4715b5f6d83d4e7be188",
      "38c67a0ccfc54f8c9e852fe3562b33a5",
      "28ccb722944547bda481436ce2ae21f5",
      "bc9219c2f85948949fd43d4c0eb74571",
      "effc4c7cccf84490ab67799fc2dde539",
      "92e303455a8e40e1827d666961614dfc",
      "e414b83de566414fadf51c4cb9112598",
      "09d2cd8766b64ff68f30f0ad2caade06",
      "5100dfd51f0645359c7f957f27eb6fe0",
      "e7fc36fbb90a48a9bbe336e77f69ad00",
      "b9a4f76fff8b4508925aa4cc60428fa0",
      "e6ac38f38b654a0dac7a9c71be6a3b29",
      "f2b03de1cc224804afba907727f8d7ec",
      "bbcc47ee41cd4b9aa9e5a5a90ec93a10",
      "789c2ee81da34af9b88d3aa48ba43d53",
      "b246e9ab7523428e9b132f5dbda2114f",
      "2a25434d938f43b2bd6f646de3c571f1",
      "d14b0c5fa67d40629f2ec8d8ed3dedb7",
      "c0d1d3e24272443887a5aa4032b2c810",
      "0483d121df2942d68ec84a30772fa795",
      "2dbae6e4c61747a88000874a6c3c49b0",
      "6e5954c1260d4020ae98ae932e122912",
      "d43a81917fa54e6992900d47d1bda1d6",
      "c6c2576c6a194bf3ba7fcff10861d0e6",
      "0bc10fd4153b414b81efb41dec260ed7",
      "8801a9905bb4481a907f8814213a421a",
      "8688ef7e3b41426eb0050f21dc7a300b",
      "64514e36c8104da5b37e17cdbac86ed0",
      "e8c8d282508b4d6da6f3baaf0f4be55f",
      "1e6653eb47ed4d3582dc3aa1ddab23e2",
      "4ef4e0aa33be4e6984a941c0dfb970f8",
      "f6f9b2ba15854d58bc5ea24a9c4e3ddb",
      "321f4a4f94c4464f82e0de62e076e5ba",
      "b7668031d7894fdab758e314887694b2",
      "eb7756dd283c4ded909163289a8273c8",
      "575c6cf6d4a549ef86ddc888d136301f",
      "a726d2c2fc0d4e92b2a51b0c27716a51",
      "ec3eb52d1f1f4661931e9bf99bad823a",
      "1a670399bf2844b789a3bc578d8d24d5",
      "cfda141e1ace4518940712eb2b038cf6",
      "b2886656b36446cd98715fadf9528c40",
      "101e854c236d447aa44c123b22bef313",
      "d5794f67d77b4e6a8fb1974dd3b1f652",
      "704057b9d2294783902aace008c44fdc",
      "c129d621f1674c9ca9abbbafe6ddf03e",
      "c4a2b69163cc43ddaf5d701893bfbe01",
      "6a7a64e8bbce4d81ab30fe5f885ecb71",
      "4e45a83412ef40db8b0242a477d2692a",
      "7737e5fbaa0b42a4bc75b85de4bd0392",
      "f9b110fdba6945e3bddc75d6785596ed",
      "8a5f4c79746840b9942d4530bce579d5",
      "69982606b8a741e4aaea82f3d6511c42",
      "2550fa5d25c743a09d72af98a9e57ec8",
      "0fadf54d316f4bdcbaa2264a9728f993",
      "02918a920d8945ada44e5d3f690bd6da",
      "33373bda358d4be6b11deec0f7ff2fa5",
      "39944e8633cc4e7491b20adff9f1037b",
      "7a3b32324e2447fab5ab2ab2768c6afc",
      "d56cac3479e94b8ea6f42e52262910b6",
      "37213b351cda4947893bcbc637b00d23",
      "7267b794d9d8483db792529d9727d55f",
      "336a44ca1a6a420f83d7fa4e9d348a9f",
      "8e68dc8f244b4b299185f85e4e0aac8b",
      "40818b3cdddc4b549ae384b8eb2073ed",
      "15d0426bca6141f9bb29813796803538",
      "6d1226c525e44e0dab9eed5c40e0734d",
      "933e9ae726384ecf87d24d0774c9697a",
      "7b3dfaa1e05d4e5d87373eb59ca12ec9",
      "63ec610bb2ec417ca5a7d7053a87fa56",
      "e209eb9785c949b498685bc1e0091662",
      "943665dbac354ce583165cd2505d7d87",
      "233723a83627424fae1c80ac0021ba00",
      "a1f3d7f834754ad5a87d7237e9d4c0a9",
      "a133485bce5a4aafa628f0d5bdc7abcf",
      "33fdc97244b948fe8f3611530d07aeb4",
      "95dab0bd71764d8bb76605ff2eff079a",
      "96586d3bf9f946c4ba4ff3f5757bc00c",
      "415174bbdf2946a0864c8ffab4acf6a2",
      "fce30377dcc04e02ac9437a0bd4d2827",
      "8dd9b0bebc0d40d4af3427d844efaaed",
      "7f7eb0c85e9841618c29503d64693dc5",
      "2983323d8b2b460abe854f147b05252a",
      "8446b64dd2804898873363cb86cb7f46",
      "7e24febce8e64b4bbeb2438edf626cb6",
      "053abf959fce4e9a98bbe931a36b7661",
      "d5dcd99ae6504d6c8c96a1e4d2853876",
      "63d94f1ad1cd4152818b67bb5347b4f6",
      "be8384d8fffd4285a0064606c386e7bc",
      "a53a96f2c8074ec2a0f51f29aed4d3c6",
      "a519304476bc467ca5be30f8b722cc03"
     ]
    },
    "id": "D4G2mc1sI-o-",
    "outputId": "ed86243d-3e41-446b-c771-4706d8e8c679"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3245c86c631941029b478ebef524a22b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc85e69fd6974d0c84f4d74607a3cce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4c171ce0884d91a8a33e4f73b069d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65bf21eaed7c4753808998466752329f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30043d448529466ca4ae867e6a776faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61358764a1384b4f904c8cdadf3f9cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ccb722944547bda481436ce2ae21f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbcc47ee41cd4b9aa9e5a5a90ec93a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc10fd4153b414b81efb41dec260ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575c6cf6d4a549ef86ddc888d136301f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7a64e8bbce4d81ab30fe5f885ecb71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3b32324e2447fab5ab2ab2768c6afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ec610bb2ec417ca5a7d7053a87fa56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd9b0bebc0d40d4af3427d844efaaed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "gpt2_model.config.pad_token_id = gpt2_tokenizer.eos_token_id\n",
    "\n",
    "clf = pipeline(\"text-classification\", model=\"jy46604790/Fake-News-Bert-Detect\", tokenizer=\"jy46604790/Fake-News-Bert-Detect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUVCJx_vJIDi"
   },
   "source": [
    "## Step 3 : Defining Generation and Detection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ey3oAKIWJSru"
   },
   "outputs": [],
   "source": [
    "def generate_fake_news(prompt=\"Breaking News:\"):\n",
    "    input_ids = gpt2_tokenizer.encode(prompt, return_tensors='pt')\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "    outputs = gpt2_model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=30,\n",
    "        num_return_sequences=5,\n",
    "        do_sample=True,\n",
    "        temperature=0.9,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        pad_token_id=gpt2_tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    headlines = []\n",
    "    for output in outputs:\n",
    "        headline = gpt2_tokenizer.decode(output, skip_special_tokens=True)\n",
    "        headlines.append(headline)\n",
    "    return \"\\n\".join([f\"{i+1}. {h}\" for i, h in enumerate(headlines)])\n",
    "\n",
    "\n",
    "def detect_fake_news(text):\n",
    "    result = clf(text[:500])[0]\n",
    "    label = \"FAKE\" if result['label'] == \"LABEL_0\" else \"REAL\"\n",
    "    confidence = round(result['score'] * 100, 2)\n",
    "    return f\"ğŸ“ Input: {text}\\n Prediction: {label}\\n Confidence: {confidence}%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EA_d0zXgKP0W"
   },
   "source": [
    "## Step 4 : Creating the Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fw8Ds3OAKWGD"
   },
   "outputs": [],
   "source": [
    "def gradio_interface(task, text):\n",
    "    if task == \"Generate Fake News\":\n",
    "        return generate_fake_news(text if text else \"Breaking News:\")\n",
    "    elif task == \"Detect Real/Fake\":\n",
    "        return detect_fake_news(text)\n",
    "    else:\n",
    "        return \"Invalid task.\"\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=gradio_interface,\n",
    "    inputs=[\n",
    "        gr.Dropdown([\"Generate Fake News\", \"Detect Real/Fake\"], label=\"Choose Task\"),\n",
    "        gr.Textbox(lines=2, placeholder=\"Enter a prompt or headline...\", label=\"Input Text\")\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"ğŸ“° Fake News Generator & Detector\",\n",
    "    description=\"Use GPT-2 to generate fake news headlines or BERT to detect whether a headline is real or fake.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FpjSzDHKsfM"
   },
   "source": [
    "## Step 5 : Launching the Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650
    },
    "id": "aRk9aZnoKymX",
    "outputId": "6d4543db-69c7-4833-c368-f0a547375b62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://6bc7968f31f6706222.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://6bc7968f31f6706222.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-wZZdF-OQ4F"
   },
   "source": [
    "![Fake News Generation](GeneratedDemo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlEzM7DuPTwx"
   },
   "source": [
    "![Fake News Detection Demo](DetectDemo1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IymJsj7Pbyf"
   },
   "source": [
    "![Fake News Detection Demo](DetectDemo2.png)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
