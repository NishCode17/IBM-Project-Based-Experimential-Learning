{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XslpQb3MAxdu",
    "outputId": "34cbddbf-2c6a-4cfb-c25a-888642ef6808"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets torch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wtlRy7hwDSRu"
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCM9OkQDEbYE",
    "outputId": "c20ea3a3-51ed-4d3b-ee8c-15788cb18680"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "clf = pipeline(\"text-classification\", model=\"jy46604790/Fake-News-Bert-Detect\", tokenizer=\"jy46604790/Fake-News-Bert-Detect\")\n",
    "\n",
    "def detect_fake_news(text):\n",
    "    result = clf(text[:500])[0]  # truncates after 500 chars\n",
    "    label = \"FAKE\" if result['label']==\"LABEL_0\" else \"REAL\"\n",
    "    print(f\"\\nInput: {text}\")\n",
    "    print(f\"Prediction: {label} (Confidence: {result['score']:.2f})\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSdP4clSEu7z",
    "outputId": "5be5f97c-4efc-4601-a48c-9ab0f8fd1f94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fake News Generator & Detector\n",
      "\n",
      "\n",
      "Choose an option:\n",
      "1 - Generate Fake News Headlines using GPT-2\n",
      "2 - Detect Fake/Real Headline using BERT\n",
      "Type 'exit' to quit.\n",
      "Enter 1 / 2 / exit: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Generated Fake Headlines:\n",
      "\n",
      "1. Breaking News: Trump tells supporters to watch his Twitter feed\n",
      "\n",
      "The two men have been photographed with the woman at the White House as she sits next\n",
      "2. Breaking News: U.S. government shut down nuclear reactor in Afghanistan\n",
      "\n",
      "U.S. defense officials have said that the move was in response\n",
      "3. Breaking News: White House Chief of Staff John Kelly speaks to a crowd of supporters at Trump National Golf Club in Bedminster, N.J., on\n",
      "4. Breaking News: Is Trump going to get it done now?\n",
      "\n",
      "We reached out to White House press secretary Josh Earnest and to the Trump campaign\n",
      "5. Breaking News: Trump Signs Bill to Make Illegal Immigration Covered by Immigration Law - Breitbart News https://t.co/f5F2Mj\n",
      "\n",
      "Choose an option:\n",
      "1 - Generate Fake News Headlines using GPT-2\n",
      "2 - Detect Fake/Real Headline using BERT\n",
      "Type 'exit' to quit.\n",
      "Enter 1 / 2 / exit: 2\n",
      "\n",
      " Enter a news headline (type 'exit' to go back):\n",
      "📝 Headline: Argentina won world cup\n",
      "\n",
      "Input: Argentina won world cup\n",
      "Prediction: REAL (Confidence: 0.95)\n",
      "\n",
      "📝 Headline: America passes a law banning russian companies\n",
      "\n",
      "Input: America passes a law banning russian companies\n",
      "Prediction: FAKE (Confidence: 1.00)\n",
      "\n",
      "📝 Headline: Modi wins his 3rd term in general elections\n",
      "\n",
      "Input: Modi wins his 3rd term in general elections\n",
      "Prediction: REAL (Confidence: 1.00)\n",
      "\n",
      "📝 Headline: Trump wins his 2nd term\n",
      "\n",
      "Input: Trump wins his 2nd term\n",
      "Prediction: FAKE (Confidence: 0.98)\n",
      "\n",
      "📝 Headline: exit\n",
      "\n",
      "Choose an option:\n",
      "1 - Generate Fake News Headlines using GPT-2\n",
      "2 - Detect Fake/Real Headline using BERT\n",
      "Type 'exit' to quit.\n",
      "Enter 1 / 2 / exit: exit\n",
      "👋 Exiting the system. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Fake News Generator & Detector\\n\")\n",
    "\n",
    "while True:\n",
    "    print(\"\\nChoose an option:\")\n",
    "    print(\"1 - Generate Fake News Headlines using GPT-2\")\n",
    "    print(\"2 - Detect Fake/Real Headline using BERT\")\n",
    "    print(\"Type 'exit' to quit.\")\n",
    "\n",
    "    choice = input(\"Enter 1 / 2 / exit: \").strip().lower()\n",
    "\n",
    "    if choice == '1':\n",
    "        prompt = \"Breaking News:\"\n",
    "        input_ids = gpt2_tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "        outputs = gpt2_model.generate(\n",
    "            input_ids,\n",
    "            max_length=30,\n",
    "            num_return_sequences=5,\n",
    "            do_sample=True,\n",
    "            temperature=0.9,\n",
    "            top_k=50,\n",
    "            top_p=0.95\n",
    "        )\n",
    "\n",
    "        print(\"\\n Generated Fake Headlines:\\n\")\n",
    "        for i, output in enumerate(outputs):\n",
    "            headline = gpt2_tokenizer.decode(output, skip_special_tokens=True)\n",
    "            print(f\"{i+1}. {headline}\")\n",
    "\n",
    "    elif choice == '2':\n",
    "        print(\"\\n Enter a news headline (type 'exit' to go back):\")\n",
    "        while True:\n",
    "            text = input(\"📝 Headline: \").strip()\n",
    "            if text.lower() == 'exit':\n",
    "                break\n",
    "            detect_fake_news(text)\n",
    "\n",
    "    elif choice == 'exit':\n",
    "        print(\"👋 Exiting the system. Goodbye!\")\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid input. Please enter 1, 2, or 'exit'.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
